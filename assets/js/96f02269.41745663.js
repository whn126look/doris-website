"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["247021"],{95342:function(e,n,i){i.r(n),i.d(n,{metadata:()=>a,contentTitle:()=>r,default:()=>u,assets:()=>o,toc:()=>d,frontMatter:()=>l});var a=JSON.parse('{"id":"table-design/auto-increment","title":"Auto-Increment Column","description":"\x3c!--","source":"@site/docs/table-design/auto-increment.md","sourceDirName":"table-design","slug":"/table-design/auto-increment","permalink":"/docs/dev/table-design/auto-increment","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Auto-Increment Column","language":"en"},"sidebar":"docs","previous":{"title":"Remote Storage","permalink":"/docs/dev/table-design/tiered-storage/remote-storage"},"next":{"title":"Best Practices","permalink":"/docs/dev/table-design/best-practice"}}'),t=i("785893"),s=i("250065");let l={title:"Auto-Increment Column",language:"en"},r=void 0,o={},d=[{value:"Functionality",id:"functionality",level:2},{value:"Uniqueness",id:"uniqueness",level:3},{value:"Density",id:"density",level:3},{value:"Syntax",id:"syntax",level:2},{value:"Examples",id:"examples",level:3},{value:"Constraints and Limitations",id:"constraints-and-limitations",level:3},{value:"Usage",id:"usage",level:2},{value:"Import",id:"import",level:3},{value:"Partial Update",id:"partial-update",level:3},{value:"Usage Scenarios",id:"usage-scenarios",level:2},{value:"Dictionary Encoding",id:"dictionary-encoding",level:3},{value:"Efficient Pagination",id:"efficient-pagination",level:3}];function c(e){let n={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.p,{children:["When importing data, Doris automatically assigns unique values to rows that do not have specified values in the ",(0,t.jsx)(n.strong,{children:"auto-increment column"}),". This feature simplifies data import workflows while maintaining flexibility."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"functionality",children:"Functionality"}),"\n",(0,t.jsx)(n.p,{children:"For tables with an auto-increment column, Doris processes data imports as follows:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Auto-Population (Column Excluded)"}),":\nIf the imported data does not include the auto-increment column, Doris generates and populates unique values for this column."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Partial Specification (Column Included)"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Null Values"}),": Doris replaces null values in the imported data with system-generated unique values."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Non-Null Values"}),": User-provided values remain unchanged."]}),"\n"]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Important"}),": User-provided non-null values can disrupt the uniqueness of the auto-increment column."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"uniqueness",children:"Uniqueness"}),"\n",(0,t.jsxs)(n.p,{children:["Doris guarantees ",(0,t.jsx)(n.strong,{children:"table-wide uniqueness"})," for values it generates in the auto-increment column. However:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Guaranteed Uniqueness"}),": This applies only to system-generated values."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"User-Provided Values"}),": Doris does not validate or enforce uniqueness for values specified by users in the auto-increment column. This may result in duplicate entries."]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"density",children:"Density"}),"\n",(0,t.jsxs)(n.p,{children:["Auto-increment values generated by Doris are generally ",(0,t.jsx)(n.strong,{children:"dense"})," but with some considerations:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Potential Gaps"}),": Gaps may appear due to performance optimizations. Each backend node (BE) pre-allocates a block of unique values for efficiency, and these blocks do not overlap between nodes."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Non-Chronological Values"}),": Doris does not guarantee that values generated in later imports are larger than those from earlier imports.\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note"}),": Auto-increment values cannot be used to infer the chronological order of imports."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"syntax",children:"Syntax"}),"\n",(0,t.jsxs)(n.p,{children:["To use auto-increment columns, you need to add the ",(0,t.jsx)(n.code,{children:"AUTO_INCREMENT"})," attribute to the corresponding column during table creation (",(0,t.jsx)(n.a,{href:"../sql-manual/sql-statements/Data-Definition-Statements/Create/CREATE-TABLE",children:"CREATE-TABLE"}),"). To manually specify the starting value for an auto-increment column, you can do so by using the ",(0,t.jsx)(n.code,{children:"AUTO_INCREMENT(start_value)"})," statement when creating the table. If not specified, the default starting value is 1."]}),"\n",(0,t.jsx)(n.h3,{id:"examples",children:"Examples"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Creating a duplicate table with an auto-increment column as the key column."}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE `demo`.`tbl` (\n        `id` BIGINT NOT NULL AUTO_INCREMENT,\n        `value` BIGINT NOT NULL\n) ENGINE=OLAP\nDUPLICATE KEY(`id`)\nDISTRIBUTED BY HASH(`id`) BUCKETS 10\nPROPERTIES (\n"replication_allocation" = "tag.location.default: 3"\n);\n\n2. Creating a duplicate table with an auto-increment column as the key column, and setting the starting value to 100.\n\n```sql\nCREATE TABLE `demo`.`tbl` (\n      `id` BIGINT NOT NULL AUTO_INCREMENT(100),\n      `value` BIGINT NOT NULL\n) ENGINE=OLAP\nDUPLICATE KEY(`id`)\nDISTRIBUTED BY HASH(`id`) BUCKETS 10\nPROPERTIES (\n"replication_allocation" = "tag.location.default: 3"\n);\n'})}),"\n",(0,t.jsxs)(n.ol,{start:"3",children:["\n",(0,t.jsx)(n.li,{children:"Creating a duplicate table with an auto-increment column as one of the value columns."}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE `demo`.`tbl` (\n    `uid` BIGINT NOT NULL,\n    `name` BIGINT NOT NULL,\n    `id` BIGINT NOT NULL AUTO_INCREMENT,\n    `value` BIGINT NOT NULL\n) ENGINE=OLAP\nDUPLICATE KEY(`uid`, `name`)\nDISTRIBUTED BY HASH(`uid`) BUCKETS 10\nPROPERTIES (\n"replication_allocation" = "tag.location.default: 3"\n);\n'})}),"\n",(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsx)(n.li,{children:"Creating a unique table with an auto-increment column as the key column."}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE `demo`.`tbl` (\n      `id` BIGINT NOT NULL AUTO_INCREMENT,\n      `name` varchar(65533) NOT NULL,\n      `value` int(11) NOT NULL\n) ENGINE=OLAP\nUNIQUE KEY(`id`)\nDISTRIBUTED BY HASH(`id`) BUCKETS 10\nPROPERTIES (\n"replication_allocation" = "tag.location.default: 3",\n"enable_unique_key_merge_on_write" = "true"\n);\n'})}),"\n",(0,t.jsxs)(n.ol,{start:"5",children:["\n",(0,t.jsx)(n.li,{children:"Creating a unique table with an auto-increment column as one of the value columns."}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE `demo`.`tbl` (\n      `text` varchar(65533) NOT NULL,\n      `id` BIGINT NOT NULL AUTO_INCREMENT,\n) ENGINE=OLAP\nUNIQUE KEY(`text`)\nDISTRIBUTED BY HASH(`text`) BUCKETS 10\nPROPERTIES (\n"replication_allocation" = "tag.location.default: 3",\n"enable_unique_key_merge_on_write" = "true"\n);\n'})}),"\n",(0,t.jsx)(n.h3,{id:"constraints-and-limitations",children:"Constraints and Limitations"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Auto-increment columns can only be used in Duplicate or Unique model tables."}),"\n",(0,t.jsx)(n.li,{children:"A table can have only one auto-increment column."}),"\n",(0,t.jsxs)(n.li,{children:["The auto-increment column must be of type ",(0,t.jsx)(n.code,{children:"BIGINT"})," and cannot be ",(0,t.jsx)(n.code,{children:"NULL"}),"."]}),"\n",(0,t.jsx)(n.li,{children:"The manually specified starting value for an auto-increment column must be 0 or greater."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,t.jsx)(n.h3,{id:"import",children:"Import"}),"\n",(0,t.jsx)(n.p,{children:"Consider the table below:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE `demo`.`tbl` (\n    `id` BIGINT NOT NULL AUTO_INCREMENT,\n    `name` varchar(65533) NOT NULL,\n    `value` int(11) NOT NULL\n) ENGINE=OLAP\nUNIQUE KEY(`id`)\nDISTRIBUTED BY HASH(`id`) BUCKETS 10\nPROPERTIES (\n"replication_allocation" = "tag.location.default: 3",\n"enable_unique_key_merge_on_write" = "true"\n);\n'})}),"\n",(0,t.jsxs)(n.p,{children:["When using the insert into statement to import data without including the auto-increment column ",(0,t.jsx)(n.code,{children:"id"}),",  Doris automatically generates and fills unique values for the column."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"mysql> insert into tbl(name, value) values(\"Bob\", 10), (\"Alice\", 20), (\"Jack\", 30);\nQuery OK, 3 rows affected (0.09 sec)\n{'label':'label_183babcb84ad4023_a2d6266ab73fb5aa', 'status':'VISIBLE', 'txnId':'7'}\n\nmysql> select * from tbl order by id;\n+------+-------+-------+\n| id   | name  | value |\n+------+-------+-------+\n|    1 | Bob   |    10 |\n|    2 | Alice |    20 |\n|    3 | Jack  |    30 |\n+------+-------+-------+\n3 rows in set (0.05 sec)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Similarly, when using stream load to import the file ",(0,t.jsx)(n.code,{children:"test.csv"})," without specifying the auto-increment column ",(0,t.jsx)(n.code,{children:"id"}),", Doris will automatically populate the ",(0,t.jsx)(n.code,{children:"id"})," column with generated values."]}),"\n",(0,t.jsx)(n.p,{children:"test.csv:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Tom, 40\nJohn, 50\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'curl --location-trusted -u user:passwd -H "columns:name,value" -H "column_separator:," -T ./test1.csv http://{host}:{port}/api/{db}/tbl/_stream_load\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"mysql> select * from tbl order by id;\n+------+-------+-------+\n| id   | name  | value |\n+------+-------+-------+\n|    1 | Bob   |    10 |\n|    2 | Alice |    20 |\n|    3 | Jack  |    30 |\n|    4 | Tom   |    40 |\n|    5 | John  |    50 |\n+------+-------+-------+\n5 rows in set (0.04 sec)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["When importing data using the ",(0,t.jsx)(n.code,{children:"INSERT INTO"})," statement and specifying the auto-increment column ",(0,t.jsx)(n.code,{children:"id"}),", any null values in the imported data for that column will be replaced with generated values."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"mysql> insert into tbl(id, name, value) values(null, \"Doris\", 60), (null, \"Nereids\", 70);\nQuery OK, 2 rows affected (0.07 sec)\n{'label':'label_9cb0c01db1a0402c_a2b8b44c11ce4703', 'status':'VISIBLE', 'txnId':'10'}\n\nmysql> select * from tbl order by id;\n+------+---------+-------+\n| id   | name    | value |\n+------+---------+-------+\n|    1 | Bob     |    10 |\n|    2 | Alice   |    20 |\n|    3 | Jack    |    30 |\n|    4 | Tom     |    40 |\n|    5 | John    |    50 |\n|    6 | Doris   |    60 |\n|    7 | Nereids |    70 |\n+------+---------+-------+\n7 rows in set (0.04 sec)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"partial-update",children:"Partial Update"}),"\n",(0,t.jsx)(n.p,{children:"When performing a partial update on a merge-on-write Unique table with an auto-increment column:"}),"\n",(0,t.jsx)(n.p,{children:"If the auto-increment column is a key column, users must explicitly specify it during partial updates. As a result, the target columns for partial updates must include the auto-increment column. In this case, the import behavior aligns with that of standard partial updates."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"mysql> CREATE TABLE `demo`.`tbl2` (\n    ->     `id` BIGINT NOT NULL AUTO_INCREMENT,\n    ->     `name` varchar(65533) NOT NULL,\n    ->     `value` int(11) NOT NULL DEFAULT \"0\"\n    -> ) ENGINE=OLAP\n    -> UNIQUE KEY(`id`)\n    -> DISTRIBUTED BY HASH(`id`) BUCKETS 10\n    -> PROPERTIES (\n    -> \"replication_allocation\" = \"tag.location.default: 3\",\n    -> \"enable_unique_key_merge_on_write\" = \"true\"\n    -> );\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> insert into tbl2(id, name, value) values(1, \"Bob\", 10), (2, \"Alice\", 20), (3, \"Jack\", 30);\nQuery OK, 3 rows affected (0.14 sec)\n{'label':'label_5538549c866240b6_bce75ef323ac22a0', 'status':'VISIBLE', 'txnId':'1004'}\n\nmysql> select * from tbl2 order by id;\n+------+-------+-------+\n| id   | name  | value |\n+------+-------+-------+\n|    1 | Bob   |    10 |\n|    2 | Alice |    20 |\n|    3 | Jack  |    30 |\n+------+-------+-------+\n3 rows in set (0.08 sec)\n\nmysql> set enable_unique_key_partial_update=true;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> set enable_insert_strict=false;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> insert into tbl2(id, name) values(1, \"modified\"), (4, \"added\");\nQuery OK, 2 rows affected (0.06 sec)\n{'label':'label_3e68324cfd87457d_a6166cc0a878cfdc', 'status':'VISIBLE', 'txnId':'1005'}\n\nmysql> select * from tbl2 order by id;\n+------+----------+-------+\n| id   | name     | value |\n+------+----------+-------+\n|    1 | modified |    10 |\n|    2 | Alice    |    20 |\n|    3 | Jack     |    30 |\n|    4 | added    |     0 |\n+------+----------+-------+\n4 rows in set (0.04 sec)\n"})}),"\n",(0,t.jsx)(n.p,{children:"When the auto-increment column is a non-key column and no value is provided, its value will be derived from existing rows in the table. If a value is specified for the auto-increment column, null values in the imported data will be replaced with generated values, while non-null values will remain unchanged. These records will then be processed according to the semantics of partial updates."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"mysql> CREATE TABLE `demo`.`tbl3` (\n    ->     `id` BIGINT NOT NULL,\n    ->     `name` varchar(100) NOT NULL,\n    ->     `score` BIGINT NOT NULL,\n    ->     `aid` BIGINT NOT NULL AUTO_INCREMENT\n    -> ) ENGINE=OLAP\n    -> UNIQUE KEY(`id`)\n    -> DISTRIBUTED BY HASH(`id`) BUCKETS 1\n    -> PROPERTIES (\n    -> \"replication_allocation\" = \"tag.location.default: 3\",\n    -> \"enable_unique_key_merge_on_write\" = \"true\"\n    -> );\nQuery OK, 0 rows affected (0.16 sec)\n\nmysql> insert into tbl3(id, name, score) values(1, \"Doris\", 100), (2, \"Nereids\", 200), (3, \"Bob\", 300);\nQuery OK, 3 rows affected (0.28 sec)\n{'label':'label_c52b2c246e244dda_9b91ee5e27a31f9b', 'status':'VISIBLE', 'txnId':'2003'}\n\nmysql> select * from tbl3 order by id;\n+------+---------+-------+------+\n| id   | name    | score | aid  |\n+------+---------+-------+------+\n|    1 | Doris   |   100 |    0 |\n|    2 | Nereids |   200 |    1 |\n|    3 | Bob     |   300 |    2 |\n+------+---------+-------+------+\n3 rows in set (0.13 sec)\n\nmysql> set enable_unique_key_partial_update=true;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> set enable_insert_strict=false;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> insert into tbl3(id, score) values(1, 999), (2, 888);\nQuery OK, 2 rows affected (0.07 sec)\n{'label':'label_dfec927d7a4343ca_9f9ade581391de97', 'status':'VISIBLE', 'txnId':'2004'}\n\nmysql> select * from tbl3 order by id;\n+------+---------+-------+------+\n| id   | name    | score | aid  |\n+------+---------+-------+------+\n|    1 | Doris   |   999 |    0 |\n|    2 | Nereids |   888 |    1 |\n|    3 | Bob     |   300 |    2 |\n+------+---------+-------+------+\n3 rows in set (0.06 sec)\n\nmysql> insert into tbl3(id, aid) values(1, 1000), (3, 500);\nQuery OK, 2 rows affected (0.07 sec)\n{'label':'label_b26012959f714f60_abe23c87a06aa0bf', 'status':'VISIBLE', 'txnId':'2005'}\n\nmysql> select * from tbl3 order by id;\n+------+---------+-------+------+\n| id   | name    | score | aid  |\n+------+---------+-------+------+\n|    1 | Doris   |   999 | 1000 |\n|    2 | Nereids |   888 |    1 |\n|    3 | Bob     |   300 |  500 |\n+------+---------+-------+------+\n3 rows in set (0.06 sec)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"usage-scenarios",children:"Usage Scenarios"}),"\n",(0,t.jsx)(n.h3,{id:"dictionary-encoding",children:"Dictionary Encoding"}),"\n",(0,t.jsx)(n.p,{children:"Using bitmaps for audience analysis in user profiling involves creating a user dictionary, where each user is assigned a unique integer as their dictionary value. Aggregating these dictionary values can improve the performance of bitmap operations."}),"\n",(0,t.jsx)(n.p,{children:"For example, in an offline UV (Unique Visitors) and PV (Page Views) analysis scenario, consider a detailed user behavior table:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE `demo`.`dwd_dup_tbl` (\n    `user_id` varchar(50) NOT NULL,\n    `dim1` varchar(50) NOT NULL,\n    `dim2` varchar(50) NOT NULL,\n    `dim3` varchar(50) NOT NULL,\n    `dim4` varchar(50) NOT NULL,\n    `dim5` varchar(50) NOT NULL,\n    `visit_time` DATE NOT NULL\n) ENGINE=OLAP\nDUPLICATE KEY(`user_id`)\nDISTRIBUTED BY HASH(`user_id`) BUCKETS 32\nPROPERTIES (\n"replication_allocation" = "tag.location.default: 3"\n);\n'})}),"\n",(0,t.jsx)(n.p,{children:"Using the auto-increment column to create the following dictionary table:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE `demo`.`dictionary_tbl` (\n    `user_id` varchar(50) NOT NULL,\n    `aid` BIGINT NOT NULL AUTO_INCREMENT\n) ENGINE=OLAP\nUNIQUE KEY(`user_id`)\nDISTRIBUTED BY HASH(`user_id`) BUCKETS 32\nPROPERTIES (\n"replication_allocation" = "tag.location.default: 3",\n"enable_unique_key_merge_on_write" = "true"\n);\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Import the ",(0,t.jsx)(n.code,{children:"user_id"})," values from existing data into the dictionary table to map ",(0,t.jsx)(n.code,{children:"user_id"})," to corresponding integer values:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"insert into dictionary_tbl(user_id)\nselect user_id from dwd_dup_tbl group by user_id;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Alternatively, import only the ",(0,t.jsx)(n.code,{children:"user_id"})," values from incremental data into the dictionary table."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"insert into dictionary_tbl(user_id)\nselect dwd_dup_tbl.user_id from dwd_dup_tbl left join dictionary_tbl\non dwd_dup_tbl.user_id = dictionary_tbl.user_id where dwd_dup_tbl.visit_time > '2023-12-10' and dictionary_tbl.user_id is NULL;\n"})}),"\n",(0,t.jsx)(n.p,{children:"In practical applications, Flink connectors can be used to write data into Doris."}),"\n",(0,t.jsxs)(n.p,{children:["To store aggregated results for the statistical dimensions ",(0,t.jsx)(n.code,{children:"dim1"}),", ",(0,t.jsx)(n.code,{children:"dim3"}),", and ",(0,t.jsx)(n.code,{children:"dim5"}),", create the following table:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE `demo`.`dws_agg_tbl` (\n    `dim1` varchar(50) NOT NULL,\n    `dim3` varchar(50) NOT NULL,\n    `dim5` varchar(50) NOT NULL,\n    `user_id_bitmap` BITMAP BITMAP_UNION NOT NULL,\n    `pv` BIGINT SUM NOT NULL \n) ENGINE=OLAP\nAGGREGATE KEY(`dim1`,`dim3`,`dim5`)\nDISTRIBUTED BY HASH(`user_id`) BUCKETS 32\nPROPERTIES (\n"replication_allocation" = "tag.location.default: 3"\n);\n'})}),"\n",(0,t.jsx)(n.p,{children:"Save the aggregated data into the results table."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"insert into dws_agg_tbl\nselect dwd_dup_tbl.dim1, dwd_dup_tbl.dim3, dwd_dup_tbl.dim5, BITMAP_UNION(TO_BITMAP(dictionary_tbl.aid)), COUNT(1)\nfrom dwd_dup_tbl INNER JOIN dictionary_tbl on dwd_dup_tbl.user_id = dictionary_tbl.user_id;\n"})}),"\n",(0,t.jsx)(n.p,{children:"Execute UV and PV queries with the following statement:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"select dim1, dim3, dim5, user_id_bitmap as uv, pv from dws_agg_tbl;\n"})}),"\n",(0,t.jsx)(n.h3,{id:"efficient-pagination",children:"Efficient Pagination"}),"\n",(0,t.jsxs)(n.p,{children:["Pagination is often required when displaying data on a page. Traditional pagination usually involves using ",(0,t.jsx)(n.code,{children:"LIMIT"}),", ",(0,t.jsx)(n.code,{children:"OFFSET"}),", and ",(0,t.jsx)(n.code,{children:"ORDER BY"})," in SQL queries. For example, consider the following business table designed for display:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE `demo`.`records_tbl` (\n    `key` int(11) NOT NULL COMMENT "",\n    `name` varchar(26) NOT NULL COMMENT "",\n    `address` varchar(41) NOT NULL COMMENT "",\n    `city` varchar(11) NOT NULL COMMENT "",\n    `nation` varchar(16) NOT NULL COMMENT "",\n    `region` varchar(13) NOT NULL COMMENT "",\n    `phone` varchar(16) NOT NULL COMMENT "",\n    `mktsegment` varchar(11) NOT NULL COMMENT ""\n) DUPLICATE KEY (`key`, `name`)\nDISTRIBUTED BY HASH(`key`) BUCKETS 10\nPROPERTIES (\n"replication_allocation" = "tag.location.default: 3"\n);\n'})}),"\n",(0,t.jsx)(n.p,{children:"Assuming 100 records are displayed per page, the following SQL query can be used to fetch data for the first page:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"select * from records_tbl order by `key`, `name` limit 100;\n"})}),"\n",(0,t.jsx)(n.p,{children:"To fetch data for the second page, you can use the following query:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"select * from records_tbl order by `key`, `name` limit 100 offset 100;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["However, when performing deep pagination queries (with large offsets), this method can be inefficient, as it reads all data into memory for sorting before processing, even if only a small number of rows are needed. By using an auto-increment column, each row is assigned a unique value, enabling the use of a query like ",(0,t.jsx)(n.code,{children:"WHERE unique_value > x LIMIT y"})," to filter out a large portion of the data in advance, making pagination more efficient."]}),"\n",(0,t.jsx)(n.p,{children:"To illustrate this, an auto-increment column is added to the business table, giving each row a unique identifier:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE `demo`.`records_tbl2` (\n    `key` int(11) NOT NULL COMMENT "",\n    `name` varchar(26) NOT NULL COMMENT "",\n    `address` varchar(41) NOT NULL COMMENT "",\n    `city` varchar(11) NOT NULL COMMENT "",\n    `nation` varchar(16) NOT NULL COMMENT "",\n    `region` varchar(13) NOT NULL COMMENT "",\n    `phone` varchar(16) NOT NULL COMMENT "",\n    `mktsegment` varchar(11) NOT NULL COMMENT "",\n    `unique_value` BIGINT NOT NULL AUTO_INCREMENT\n) DUPLICATE KEY (`key`, `name`)\nDISTRIBUTED BY HASH(`key`) BUCKETS 10\nPROPERTIES (\n    "replication_num" = "3"\n);\n'})}),"\n",(0,t.jsx)(n.p,{children:"For pagination with 100 records per page, the following SQL query can be used to fetch the data for the first page:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"select * from records_tbl2 order by unique_value limit 100;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["By recording the maximum value of ",(0,t.jsx)(n.code,{children:"unique_value"})," from the returned results, let's assume it is 99. The following query can then be used to fetch data for the second page:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"select * from records_tbl2 where unique_value > 99 order by unique_value limit 100;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["If directly querying data from a later page and it's inconvenient to retrieve the maximum value of ",(0,t.jsx)(n.code,{children:"unique_value"})," from the previous page's results (for example, when fetching data starting from the 101st page), the following query can be used:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"select key, name, address, city, nation, region, phone, mktsegment\nfrom records_tbl2, (select unique_value as max_value from records_tbl2 order by unique_value limit 1 offset 9999) as previous_data\nwhere records_tbl2.unique_value > previous_data.max_value\norder by records_tbl2.unique_value limit 100;\n"})})]})}function u(e={}){let{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},250065:function(e,n,i){i.d(n,{Z:function(){return r},a:function(){return l}});var a=i(667294);let t={},s=a.createContext(t);function l(e){let n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);